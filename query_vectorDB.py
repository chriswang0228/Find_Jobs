import json, yaml
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer

# === å¯è‡ªè¨‚æŸ¥è©¢æ–‡å­—èˆ‡ Top K æ•¸é‡ ===
query_text = f"""ã€è·ç¼ºã€‘AIå·¥ç¨‹å¸«, è³‡æ–™ç§‘å­¸å®¶
ã€å…¬å¸ã€‘å…·è¦æ¨¡çš„ç§‘æŠ€å…¬å¸ï¼Œè³‡è¨Šå…¬å¸ï¼Œå“¡å·¥è¶…é 1000 äºº
ã€æè¿°ã€‘é–‹ç™¼ NLPã€å½±åƒè¾¨è­˜ã€ç”Ÿæˆå¼ AI æ‡‰ç”¨ï¼Œä¸è¦èˆ‡éŠæˆ²ï¼Œç¶²é ï¼Œç¡¬é«”ç­‰ç›¸é—œ
ã€æŠ€èƒ½ã€‘Python, PyTorch, NLP, Computer Vision
ã€è·é¡ã€‘è»Ÿé«”å·¥ç¨‹å¸«, è³‡æ–™ç§‘å­¸å®¶
ã€è³‡æœ¬é¡ã€‘åå„„ä»¥ä¸Š
ã€æ‡‰å¾µäººæ•¸ã€‘æ‡‰å¾µè€…è¶…é 30 äºº"""

with open("config.yaml", "r", encoding="utf-8") as f:
    config = yaml.safe_load(f)

top_k = config["vector"]["top_k"]
# === è¼‰å…¥å‘é‡è³‡æ–™åº«èˆ‡æ¨¡å‹ ===
index = faiss.read_index(config["path"]["faiss_index"])

with open(config["path"]["faiss_ids"], "r", encoding="utf-8") as f:
    job_ids = json.load(f)

with open(config["path"]["filtered_jobs"], "r", encoding="utf-8") as f:
    job_data = {job["job_id"]: job for job in json.load(f)}

model = SentenceTransformer(config["vector"]["embedding_model"], device="cuda")

# === æŸ¥è©¢å‘é‡è³‡æ–™åº« ===
query_vec = model.encode([query_text])
D, I = index.search(np.array(query_vec), top_k)
results = []

for rank, idx in enumerate(I[0]):
    job_id = job_ids[idx]
    job = job_data.get(job_id)
    if not job:
        continue
    result = {
        "rank": rank + 1,
        "job_name": job["job_name"],
        "company": job["company"],
        "link": job["link"],
        "description": job["description"][:100] + "...",
    }
    results.append(result)

# === å°å‡ºçµæœ ===
print(f"ğŸ” æŸ¥è©¢ï¼šã€Œ{query_text}ã€\nTop {top_k} çµæœï¼š\n")
for res in results:
    print(f"{res['rank']}. ğŸ“Œ {res['job_name']} @ {res['company']}")
    print(f"    ğŸ”— {res['link']}")
    print(f"    ğŸ“„ {res['description']}\n")

# === å„²å­˜ JSON çµæœ ===
with open(config["path"]["search_result"], "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print("âœ… å·²å°‡çµæœå„²å­˜è‡³ search_result.json")
